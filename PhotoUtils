#ä¸‹è½½å½¼å²¸å›¾ç‰‡
# å¯¼å…¥å¿…è¦çš„åŒ…
from selenium import webdriver
from bs4 import BeautifulSoup
import requests
import os


'''
#çˆ¬å–çš„èµ„æºç±»å‹
pic_type 4kmeinv   4kfengjing   4kyouxi   4kyingshi 4kdongman 4kmingxing 4kqiche 4krenwu 4kdongwu 4kmeishi 4kzongjiao 4kbeijing
'''
pic_type = '4kdongman'
# åˆå§‹åŒ–ä¸€ä¸ªå¼•ç”¨è®¡æ•°ï¼Œç”¨äºåé¢çš„å›¾ç‰‡ç®€å•å‘½å
index = 1
#å¼€å§‹çš„é¡µæ•°
start_page=1
#ç»“æŸçš„é¡µæ•°
end_page=2
#æ‰«æçš„å›¾ç‰‡åœ°å€
image_list=[]
#è§£æåˆ°çš„æºå›¾ç‰‡åœ°å€
source_images=[]

# å®šä¹‰çˆ¬è™«æ–¹æ³•
def getImage():
    '''
        æ‰«æè·å–å›¾ç‰‡åœ°å€
    '''
    # å°†indexç½®ä¸ºå…¨å±€å˜é‡
    global index
    # å¾ªç¯çˆ¬å–ï¼Œå¾ªç¯å¤šå°‘æ¬¡çˆ¬å–å¤šå°‘é¡µçš„å›¾ç‰‡
    print('==============å¼€å§‹æœç´¢ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡==============')
    for i in range(start_page, end_page):
        # æ¨¡æ‹Ÿç‚¹å‡»ä¸‹ä¸€é¡µï¼Œå› ä¸ºçˆ¬å–å®Œä¸€é¡µéœ€è¦ç‚¹å‡»ä¸‹ä¸€é¡µçˆ¬å–
        # driver.find_element_by_link_text("ä¸‹ä¸€é¡µ").click()
        # https://pic.netbian.com/4kmeinv/index_2.html
        if i == 1:
            imageUrl = 'https://pic.netbian.com/{0}'.format(pic_type)
        else:
            imageUrl = 'https://pic.netbian.com/{0}/index_{1}.html'.format(pic_type,i)
        r = requests.get(imageUrl)
        # è§£æç½‘é¡µ
        html = BeautifulSoup(r.text, 'html.parser')
        # è·å–åŸå›¾çš„urlé“¾æ¥
        links =html.find('div', {'class': 'slist'}).find_all('a')
        for link in links:
            # éå†å½“é¡µè·å¾—çš„æ‰€æœ‰åŸå›¾é“¾æ¥
            imageUrl = "http://pic.netbian.com"  + link.get('href')
            if not str(imageUrl).__contains__(pic_type) and imageUrl not in image_list:
                image_list.append(imageUrl)
                print('ğŸŒˆ æ‰«æèµ„æº =>' + imageUrl)
    print('==============å›¾ç‰‡èµ„æºæœç´¢å®Œæ¯•==============')
    parseImageList()



def parseImageList():
    '''
    è§£æå›¾ç‰‡çš„æ“ä½œ
    '''
    print('=============æ­£åœ¨è§£ææœç´¢åˆ°çš„å›¾ç‰‡èµ„æº=============')
    for imageUrl in image_list:
        r = requests.post(imageUrl)
        html = BeautifulSoup(r.text, 'html.parser')
        # è·å–åŸå›¾çš„urlé“¾æ¥
        links = html.find('div', {'class': 'photo-pic'}).find_all('img')
        for link in links:
            source_image = "https://pic.netbian.com" + link.get('src')
            if source_image not in source_images:
                source_images.append(source_image)
                print('ğŸ‰ è§£æåˆ°èµ„æº=>' + source_image)
    print('============å›¾ç‰‡èµ„æºè§£æå®Œæ¯•==========')
    saveImage(source_images)


# ä¿å­˜å›¾ç‰‡
def saveImage(links):
    '''
    ä¿å­˜å›¾ç‰‡æ“ä½œ
    :param links: æºå›¾ç‰‡åœ°å€
    :return: è¿”å›ä¿å­˜çš„æ•°æ®
    '''
    print('==================æ­£åœ¨ä¿å­˜æ‰«æåˆ°çš„å›¾ç‰‡====================')
    images_file = os.path.join(os.path.expanduser("~"), 'Desktop') + "/images_file/"
    if not os.path.exists(images_file):
        os.makedirs(images_file)

    for index in range(0, len(links)):
        link = links[index]
        print("âœ… æ­£åœ¨çˆ¬å–å›¾ç‰‡ => %s" %link)
        # å°†åŸå›¾å­˜è‡³å½“å‰ç›®å½•ä¸‹çš„test/img æ–‡ä»¶å¤¹ï¼Œä»¥indexå‘½åï¼Œåç¼€åä¸ºå›¾ç‰‡åŸåçš„åä¸‰ä½ï¼Œå³jpgæˆ–è€…gif
        with open(images_file + '{}.{}'.format(index, link[len(link)-3: len(link)]), 'wb') as jpg:
            jpg.write(requests.get(link).content)
        index += 1
    print('============æ‰€æœ‰å›¾ç‰‡ä¿å­˜å®Œæ¯•==========')


# å®šä¹‰ä¸»å‡½æ•°
if __name__ == '__main__':
    '''
    ä¸»å‡½æ•°ï¼šè°ƒç”¨çˆ¬å–æ“ä½œ
    '''
    getImage()
